<template>
    <div class="prose dark:prose-invert lg:prose-xl">
        <h2>Welcome to the ELSA Recommendation Platform for Data Science Projects</h2>

        <p>
            As data science continues to shape the world around us, from healthcare and education to urban planning and
            policymaking, there is a growing need to ensure that the work we do is not only technically sound, but also
            ethically responsible, legally compliant, and socially aware.
        </p>

        <p>
            That’s where this platform comes in.
        </p>

        <p>
            The ELSA (Ethical, Legal, and Societal Aspects) Recommendation Platform is designed to support data
            scientists
            throughout the entire lifecycle of a project. Whether you're just starting to define your problem,
            collecting
            and preparing data, building models, or deploying results in real-world contexts, this platform helps you
            reflect on and act upon important questions like:
        </p>

        <ul>
            <li>
                <b>Are we using data responsibly?</b>
            </li>
            <li>
                <b>Have we considered the impact on individuals and communities?</b>
            </li>
            <li>
                <b>What are the legal requirements or potential risks?</b>
            </li>
            <li>
                <b>Who might be affected, and how are their interests being considered?</b>
            </li>
        </ul>

        <p>
            Instead of asking you to become an expert in ethics, law, or the social sciences, the platform offers
            practical
            guidance, curated tools, checklists, and methods tailored to each stage of the data science workflow. It
            also
            allows you to document your decisions and reflections in a structured, project-specific journal—helping you
            keep
            track of how and when these considerations have been addressed.
        </p>

        <p>
            Whether you’re part of a research team, a public-sector project, or an industry application, this platform
            aims
            to make it easier to build data-driven solutions that are not only innovative but also responsible and
            trustworthy.
        </p>

        <h3>
            What does this look like in practice?
        </h3>

        <p>
            Imagine you're building a machine learning model to predict which patients are at risk of developing a
            chronic illness. In the early planning stages, the platform might prompt you to think about potential biases
            in your training data, or whether patients have consented to their data being used in this way. You might be
            directed to a checklist for assessing data protection compliance, or a tool for mapping potential societal
            impacts.
        </p>

        <p>
            Later, when you're training and evaluating your model, the platform could recommend fairness metrics or
            guidelines for documenting model performance across different population groups. As you prepare to deploy
            the model in a clinical setting, you might receive suggestions on transparency practices or legal frameworks
            relevant to medical AI tools.
        </p>

        <p>
            At each step, your reflections and decisions are captured in your project journal—building a transparent
            record of how ethical, legal, and societal aspects have been considered and addressed.
        </p>
    </div>
</template>